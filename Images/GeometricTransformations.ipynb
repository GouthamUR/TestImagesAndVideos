{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ae84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b2afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_basic_transforms(image_path, output_dir):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image from {image_path}\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 1. Zoom In\n",
    "    zoom_in = img[h//4:3*h//4, w//4:3*w//4]\n",
    "    zoom_in = cv2.resize(zoom_in, (w, h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"zoom_in.jpg\"), zoom_in)\n",
    "\n",
    "    # 2. Zoom Out\n",
    "    zoom_out = cv2.resize(img, (w//2, h//2))\n",
    "    zoom_out = cv2.copyMakeBorder(zoom_out, h//4, h//4, w//4, w//4,\n",
    "                                  cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"zoom_out.jpg\"), zoom_out)\n",
    "\n",
    "    # 3. Rotation\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), 15, 1)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"rotated.jpg\"), rotated)\n",
    "\n",
    "    # 4. Tilt\n",
    "    pts1 = np.float32([[0,0], [w-1,0], [0,h-1]])\n",
    "    pts2 = np.float32([[0,0], [w-1, int(0.3*h)], [int(0.2*w), h-1]])\n",
    "    M_tilt = cv2.getAffineTransform(pts1, pts2)\n",
    "    tilted = cv2.warpAffine(img, M_tilt, (w, h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"tilted.jpg\"), tilted)\n",
    "\n",
    "    # 5. Flip\n",
    "    flipped = cv2.flip(img, 1)\n",
    "    cv2.imwrite(os.path.join(output_dir, \"flipped.jpg\"), flipped)\n",
    "\n",
    "    # 6. Blur\n",
    "    blurred = cv2.GaussianBlur(img, (9, 9), 0)\n",
    "    cv2.imwrite(os.path.join(output_dir, \"blurred.jpg\"), blurred)\n",
    "\n",
    "    # 7. Brightness\n",
    "    bright = cv2.convertScaleAbs(img, alpha=1.2, beta=30)\n",
    "    cv2.imwrite(os.path.join(output_dir, \"bright.jpg\"), bright)\n",
    "\n",
    "    # 8. Translation\n",
    "    M_trans = np.float32([[1, 0, 30], [0, 1, 50]])\n",
    "    translated = cv2.warpAffine(img, M_trans, (w, h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"translated.jpg\"), translated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e289f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_transformations(image_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image from {image_path}\")\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # 1. Skewing Horizontal\n",
    "    skew_matrix_h = np.array([[1, 0.3, 0], [0, 1, 0]], dtype=np.float32)\n",
    "    skewed_image_h = cv2.warpAffine(image, skew_matrix_h, (int(w * 1.3), h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"skewed_horizontal.jpg\"), skewed_image_h)\n",
    "\n",
    "    # 2. Perspective\n",
    "    pts1 = np.float32([[50, 50], [w - 50, 50], [50, h - 50], [w - 50, h - 50]])\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [100, h], [w - 100, h]])\n",
    "    perspective_matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    perspective_image = cv2.warpPerspective(image, perspective_matrix, (w, h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"perspective.jpg\"), perspective_image)\n",
    "\n",
    "    # 3. Shear\n",
    "    shear_matrix = np.float32([[1, 0.5, 0], [0, 1, 0]])\n",
    "    sheared_image = cv2.warpAffine(image, shear_matrix, (int(w + h * 0.5), h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"sheared.jpg\"), sheared_image)\n",
    "\n",
    "    # 4. Stretch\n",
    "    stretched_image = cv2.resize(image, (int(w * 1.5), h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"stretched.jpg\"), stretched_image)\n",
    "\n",
    "    # 5. Compression\n",
    "    compressed_image = cv2.resize(image, (int(w * 0.5), h))\n",
    "    cv2.imwrite(os.path.join(output_dir, \"compressed.jpg\"), compressed_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e5fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_dataset(dataset_dir, num_images=10, output_root=\"outputs\"):\n",
    "    # Ensure outputs dir exists\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    # Select images\n",
    "    all_images = [f for f in os.listdir(dataset_dir)\n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if len(all_images) < num_images:\n",
    "        raise ValueError(\"Not enough images in dataset to sample from.\")\n",
    "\n",
    "    selected = random.sample(all_images, num_images)\n",
    "\n",
    "    # Save selected images\n",
    "    selected_dir = os.path.join(output_root, \"selected\")\n",
    "    os.makedirs(selected_dir, exist_ok=True)\n",
    "\n",
    "    selected_paths = []\n",
    "    for img_name in selected:\n",
    "        src_path = os.path.join(dataset_dir, img_name)\n",
    "        dst_path = os.path.join(selected_dir, img_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        selected_paths.append(dst_path)\n",
    "\n",
    "    print(f\"Selected {num_images} images and saved in {selected_dir}\")\n",
    "\n",
    "    # Apply transformations\n",
    "    for idx, img_path in enumerate(selected_paths):\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        # Stage1 outputs\n",
    "        stage1_dir = os.path.join(output_root, \"stage1\", base_name)\n",
    "        stage1_basic_transforms(img_path, stage1_dir)\n",
    "\n",
    "        # Apply transformations outputs\n",
    "        stage2_dir = os.path.join(output_root, \"stage2\", base_name)\n",
    "        apply_transformations(img_path, stage2_dir)\n",
    "\n",
    "    print(f\"All transformations completed and saved under {output_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d49760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 images and saved in outputs\\selected\n",
      "All transformations completed and saved under outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dir = \"../Datasets/images\"\n",
    "process_dataset(dataset_dir, num_images=10, output_root=\"outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48284db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
